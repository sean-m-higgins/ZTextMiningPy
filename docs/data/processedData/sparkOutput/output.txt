2019-03-13 13:27:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-13 13:27:56 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-03-13 13:27:56 INFO  SparkContext:54 - Submitted application: LDAExample with {
  input:	List(/Users/SeanHiggins/ZTextMining/src/main/data/processedData/processedZettels),
  k:	20,
  maxIterations:	10,
  docConcentration:	-1.0,
  topicConcentration:	-1.0,
  vocabSize:	10000,
  stopwordFile:	,
  algorithm:	em,
  checkpointDir:	None,
  checkpointInterval:	10
}
2019-03-13 13:27:56 INFO  SecurityManager:54 - Changing view acls to: SeanHiggins
2019-03-13 13:27:56 INFO  SecurityManager:54 - Changing modify acls to: SeanHiggins
2019-03-13 13:27:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-13 13:27:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-13 13:27:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(SeanHiggins); groups with view permissions: Set(); users  with modify permissions: Set(SeanHiggins); groups with modify permissions: Set()
2019-03-13 13:27:57 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53280.
2019-03-13 13:27:57 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-13 13:27:57 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-13 13:27:57 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-13 13:27:57 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-13 13:27:57 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-ac945d9c-64f4-4e35-941e-621fd9fcf6b0
2019-03-13 13:27:57 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-03-13 13:27:57 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-13 13:27:57 INFO  log:192 - Logging initialized @4739ms
2019-03-13 13:27:57 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-03-13 13:27:57 INFO  Server:419 - Started @4861ms
2019-03-13 13:27:57 INFO  AbstractConnector:278 - Started ServerConnector@60325987{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-13 13:27:57 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46c269e0{/jobs,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70228253{/jobs/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63c12e52{/jobs/job,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26c47874{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@421056e5{/stages,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2849434b{/stages/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60bbacfc{/stages/stage,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476fe690{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a0e7ecd{/stages/pool,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e3658c{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43e9089{/storage,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5dbdf8{/storage/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352c44a8{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7aac8884{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a66e580{/environment,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b852b49{/environment/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdb2d95{/executors,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@122d6c22{/executors/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f5ac102{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5df778c3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@895416d{/static,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22a6e998{/,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55e42449{/api,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cb7fa71{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dffc764{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-13 13:27:57 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.24.53.199:4040
2019-03-13 13:27:57 INFO  SparkContext:54 - Added JAR file:/Users/SeanHiggins/ZTextMining/target/scala-2.11/ZTextMining-assembly-0.2.jar at spark://10.24.53.199:53280/jars/ZTextMining-assembly-0.2.jar with timestamp 1552501677904
2019-03-13 13:27:58 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-03-13 13:27:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53281.
2019-03-13 13:27:58 INFO  NettyBlockTransferService:54 - Server created on 10.24.53.199:53281
2019-03-13 13:27:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-13 13:27:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.24.53.199, 53281, None)
2019-03-13 13:27:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.24.53.199:53281 with 366.3 MB RAM, BlockManagerId(driver, 10.24.53.199, 53281, None)
2019-03-13 13:27:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.24.53.199, 53281, None)
2019-03-13 13:27:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.24.53.199, 53281, None)
2019-03-13 13:27:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2bfb583b{/metrics/json,null,AVAILABLE,@Spark}
2019-03-13 13:27:58 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.

Corpus summary:
	 Training set size: 429 documents
	 Vocabulary size: 10000 terms
	 Training set size: 61415 tokens
	 Preprocessing time: 25.542742274 sec

2019-03-13 13:30:24 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@2adc9cb2 rejected from java.util.concurrent.ThreadPoolExecutor@37d1f6b4[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 12104]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@72915559 rejected from java.util.concurrent.ThreadPoolExecutor@75cb5a79[Shutting down, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 12105]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@4d561996 rejected from java.util.concurrent.ThreadPoolExecutor@37d1f6b4[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 12104]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@37263592 rejected from java.util.concurrent.ThreadPoolExecutor@75cb5a79[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 12106]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@44314db6 rejected from java.util.concurrent.ThreadPoolExecutor@37d1f6b4[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 12104]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@574217e8 rejected from java.util.concurrent.ThreadPoolExecutor@75cb5a79[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 12106]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@1230c25f rejected from java.util.concurrent.ThreadPoolExecutor@37d1f6b4[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 12104]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:30:24 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@2100221b rejected from java.util.concurrent.ThreadPoolExecutor@75cb5a79[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 12108]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:32:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-13 13:32:21 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-03-13 13:32:22 INFO  SparkContext:54 - Submitted application: LDAExample with {
  input:	List(/Users/SeanHiggins/ZTextMining/src/main/data/processedData/processedZettels),
  k:	20,
  maxIterations:	10,
  docConcentration:	-1.0,
  topicConcentration:	-1.0,
  vocabSize:	10000,
  stopwordFile:	,
  algorithm:	em,
  checkpointDir:	None,
  checkpointInterval:	10
}
2019-03-13 13:32:22 INFO  SecurityManager:54 - Changing view acls to: SeanHiggins
2019-03-13 13:32:22 INFO  SecurityManager:54 - Changing modify acls to: SeanHiggins
2019-03-13 13:32:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-13 13:32:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-13 13:32:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(SeanHiggins); groups with view permissions: Set(); users  with modify permissions: Set(SeanHiggins); groups with modify permissions: Set()
2019-03-13 13:32:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53328.
2019-03-13 13:32:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-13 13:32:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-13 13:32:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-13 13:32:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-13 13:32:22 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-fe55f8da-cd10-46c1-9907-de00e467aebf
2019-03-13 13:32:22 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-03-13 13:32:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-13 13:32:22 INFO  log:192 - Logging initialized @3706ms
2019-03-13 13:32:22 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-03-13 13:32:22 INFO  Server:419 - Started @3797ms
2019-03-13 13:32:22 INFO  AbstractConnector:278 - Started ServerConnector@29161ad0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-13 13:32:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1effd53c{/jobs,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75ae4a1f{/jobs/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70228253{/jobs/job,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21bd20ee{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26c47874{/stages,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@421056e5{/stages/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2849434b{/stages/stage,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@255eaa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476fe690{/stages/pool,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a0e7ecd{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e3658c{/storage,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43e9089{/storage/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5dbdf8{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352c44a8{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7aac8884{/environment,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a66e580{/environment/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b852b49{/executors,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdb2d95{/executors/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@122d6c22{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f5ac102{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5df778c3{/static,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6dd1c3ed{/,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22a6e998{/api,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78054f54{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cb7fa71{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-13 13:32:22 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.24.53.199:4040
2019-03-13 13:32:22 INFO  SparkContext:54 - Added JAR file:/Users/SeanHiggins/ZTextMining/target/scala-2.11/ZTextMining-assembly-0.2.jar at spark://10.24.53.199:53328/jars/ZTextMining-assembly-0.2.jar with timestamp 1552501942900
2019-03-13 13:32:22 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-03-13 13:32:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53329.
2019-03-13 13:32:23 INFO  NettyBlockTransferService:54 - Server created on 10.24.53.199:53329
2019-03-13 13:32:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-13 13:32:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.24.53.199, 53329, None)
2019-03-13 13:32:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.24.53.199:53329 with 366.3 MB RAM, BlockManagerId(driver, 10.24.53.199, 53329, None)
2019-03-13 13:32:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.24.53.199, 53329, None)
2019-03-13 13:32:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.24.53.199, 53329, None)
2019-03-13 13:32:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2513a118{/metrics/json,null,AVAILABLE,@Spark}
2019-03-13 13:32:23 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.

Corpus summary:
	 Training set size: 429 documents
	 Vocabulary size: 10000 terms
	 Training set size: 61415 tokens
	 Preprocessing time: 23.108276055 sec

2019-03-13 13:35:21 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@4e88db69 rejected from java.util.concurrent.ThreadPoolExecutor@106cef8a[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15127]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@2d3cec37 rejected from java.util.concurrent.ThreadPoolExecutor@7a387733[Shutting down, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 15128]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@13ec536c rejected from java.util.concurrent.ThreadPoolExecutor@106cef8a[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15127]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@51340391 rejected from java.util.concurrent.ThreadPoolExecutor@7a387733[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 15129]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@3a1543e1 rejected from java.util.concurrent.ThreadPoolExecutor@106cef8a[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15127]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@401d9082 rejected from java.util.concurrent.ThreadPoolExecutor@7a387733[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 15130]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@70d56e4 rejected from java.util.concurrent.ThreadPoolExecutor@106cef8a[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15127]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:21 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@2a320efb rejected from java.util.concurrent.ThreadPoolExecutor@7a387733[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15131]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:35:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-13 13:35:51 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-03-13 13:35:51 INFO  SparkContext:54 - Submitted application: LDAExample with {
  input:	List(/Users/SeanHiggins/ZTextMining/src/main/data/processedData/processedZettels),
  k:	20,
  maxIterations:	10,
  docConcentration:	-1.0,
  topicConcentration:	-1.0,
  vocabSize:	10000,
  stopwordFile:	,
  algorithm:	em,
  checkpointDir:	None,
  checkpointInterval:	10
}
2019-03-13 13:35:52 INFO  SecurityManager:54 - Changing view acls to: SeanHiggins
2019-03-13 13:35:52 INFO  SecurityManager:54 - Changing modify acls to: SeanHiggins
2019-03-13 13:35:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-13 13:35:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-13 13:35:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(SeanHiggins); groups with view permissions: Set(); users  with modify permissions: Set(SeanHiggins); groups with modify permissions: Set()
2019-03-13 13:35:52 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53348.
2019-03-13 13:35:52 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-13 13:35:52 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-13 13:35:52 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-13 13:35:52 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-13 13:35:52 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-2c4caa37-5030-4164-9852-b948a12d1b37
2019-03-13 13:35:52 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-03-13 13:35:52 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-13 13:35:52 INFO  log:192 - Logging initialized @3590ms
2019-03-13 13:35:52 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-03-13 13:35:52 INFO  Server:419 - Started @3676ms
2019-03-13 13:35:52 INFO  AbstractConnector:278 - Started ServerConnector@60325987{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-13 13:35:52 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46c269e0{/jobs,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70228253{/jobs/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63c12e52{/jobs/job,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26c47874{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@421056e5{/stages,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2849434b{/stages/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60bbacfc{/stages/stage,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476fe690{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a0e7ecd{/stages/pool,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e3658c{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43e9089{/storage,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5dbdf8{/storage/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352c44a8{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7aac8884{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a66e580{/environment,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b852b49{/environment/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdb2d95{/executors,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@122d6c22{/executors/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f5ac102{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5df778c3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@895416d{/static,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22a6e998{/,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55e42449{/api,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cb7fa71{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dffc764{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-13 13:35:52 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.24.53.199:4040
2019-03-13 13:35:52 INFO  SparkContext:54 - Added JAR file:/Users/SeanHiggins/ZTextMining/target/scala-2.11/ZTextMining-assembly-0.2.jar at spark://10.24.53.199:53348/jars/ZTextMining-assembly-0.2.jar with timestamp 1552502152770
2019-03-13 13:35:52 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-03-13 13:35:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53349.
2019-03-13 13:35:53 INFO  NettyBlockTransferService:54 - Server created on 10.24.53.199:53349
2019-03-13 13:35:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-13 13:35:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.24.53.199, 53349, None)
2019-03-13 13:35:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.24.53.199:53349 with 366.3 MB RAM, BlockManagerId(driver, 10.24.53.199, 53349, None)
2019-03-13 13:35:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.24.53.199, 53349, None)
2019-03-13 13:35:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.24.53.199, 53349, None)
2019-03-13 13:35:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2bfb583b{/metrics/json,null,AVAILABLE,@Spark}
2019-03-13 13:35:53 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.

Corpus summary:
	 Training set size: 429 documents
	 Vocabulary size: 10000 terms
	 Training set size: 61415 tokens
	 Preprocessing time: 23.779037853 sec

2019-03-13 13:36:34 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@349f5eb6 rejected from java.util.concurrent.ThreadPoolExecutor@57200bc9[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 4469]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@35ac450b rejected from java.util.concurrent.ThreadPoolExecutor@7c9f940f[Shutting down, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 4470]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@3b8f17ad rejected from java.util.concurrent.ThreadPoolExecutor@57200bc9[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 4469]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@7bfaf18e rejected from java.util.concurrent.ThreadPoolExecutor@7c9f940f[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 4472]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@7f18a6a5 rejected from java.util.concurrent.ThreadPoolExecutor@57200bc9[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 4469]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:486)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@182537a0 rejected from java.util.concurrent.ThreadPoolExecutor@7c9f940f[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 4472]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-03-13 13:36:34 ERROR ShuffleBlockFetcherIterator:91 - Failed to create input stream from local block
java.io.IOException: Error in reading FileSegmentManagedBuffer{file=/private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-2c4caa37-5030-4164-9852-b948a12d1b37/0c/shuffle_3_382_0.data, offset=3592, length=51}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:111)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.graphx.impl.RoutingTablePartition$.fromMsgs(RoutingTablePartition.scala:68)
	at org.apache.spark.graphx.VertexRDD$$anonfun$createRoutingTables$1.apply(VertexRDD.scala:362)
	at org.apache.spark.graphx.VertexRDD$$anonfun$createRoutingTables$1.apply(VertexRDD.scala:362)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-2c4caa37-5030-4164-9852-b948a12d1b37/0c/shuffle_3_382_0.data (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:100)
	... 56 more
2019-03-13 13:36:34 WARN  BlockManager:66 - Putting block rdd_29_179 failed due to exception org.apache.spark.shuffle.FetchFailedException: Error in reading FileSegmentManagedBuffer{file=/private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-2c4caa37-5030-4164-9852-b948a12d1b37/0c/shuffle_3_382_0.data, offset=3592, length=51}.
2019-03-13 13:36:34 WARN  BlockManager:66 - Block rdd_29_179 could not be removed as it was not found on disk or in memory
2019-03-13 13:36:34 WARN  BlockManager:66 - Putting block rdd_41_179 failed due to exception org.apache.spark.shuffle.FetchFailedException: Error in reading FileSegmentManagedBuffer{file=/private/var/folders/tp/qc0shgmd5y36vv48mt20b0z00000gn/T/blockmgr-2c4caa37-5030-4164-9852-b948a12d1b37/0c/shuffle_3_382_0.data, offset=3592, length=51}.
2019-03-13 13:36:34 WARN  BlockManager:66 - Block rdd_41_179 could not be removed as it was not found on disk or in memory
2019-03-13 13:36:34 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@da385ab rejected from java.util.concurrent.ThreadPoolExecutor@7c9f940f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 4473]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:200)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:88)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:86)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:86)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
